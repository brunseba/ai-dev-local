model_list:
  # OpenAI Models
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: os.environ/OPENAI_API_KEY
  
  - model_name: gpt-4-turbo
    litellm_params:
      model: openai/gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
  
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY

  # Anthropic Models  
  - model_name: claude-3-opus
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-3-sonnet
    litellm_params:
      model: anthropic/claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY

  # Google Models
  - model_name: gemini-pro
    litellm_params:
      model: gemini/gemini-pro
      api_key: os.environ/GEMINI_API_KEY

  # Cohere Models
  - model_name: command-r-plus
    litellm_params:
      model: cohere/command-r-plus
      api_key: os.environ/COHERE_API_KEY

  # Local Ollama Models (if available)
  - model_name: llama2
    litellm_params:
      model: ollama/llama2
      api_base: http://host.docker.internal:11434

  - model_name: codellama
    litellm_params:
      model: ollama/codellama
      api_base: http://host.docker.internal:11434

# Router settings
router_settings:
  routing_strategy: usage-based-routing
  model_group_alias:
    gpt-4-group: ["gpt-4", "gpt-4-turbo"]
    claude-group: ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]
  
# General settings
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  
  # Cost tracking
  track_cost_per_model: True
  
  # Caching
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  cache: True
  cache_params:
    type: "redis"
    ttl: 600
  
  # Rate limiting
  max_budget: 100
  budget_duration: 30d
  
  # Logging
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  
  # Langfuse integration
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST

# Proxy settings
litellm_settings:
  telemetry: false
  json_logs: true
  log_level: INFO
  
  # Request settings
  request_timeout: 600
  max_retries: 3
  
  # UI settings
  ui_access_mode: "admin_only"
  ui_username: os.environ/UI_USERNAME
  ui_password: os.environ/UI_PASSWORD
